{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cae97eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install -q chromadb langchain langchain_openai langchain_community sentence-transformers python-dotenv requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "255d9c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import Any, List, Mapping, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41e6d636",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import libraries\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.language_models import LLM\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import requests\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c11ce7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deeb15d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OpenRouter model: openai/gpt-3.5-turbo\n",
      "OpenRouter API key loaded: Yes\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "openrouter_model = os.getenv(\"OPENROUTER_MODEL\", \"openai/gpt-3.5-turbo\")\n",
    "\n",
    "print(f\"Using OpenRouter model: {openrouter_model}\")\n",
    "print(f\"OpenRouter API key loaded: {'Yes' if openrouter_api_key else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8510f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RobustOpenRouterLLM(LLM):\n",
    "    \"\"\"Enhanced OpenRouter LLM with better error handling\"\"\"\n",
    "    \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"openrouter\"\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {openrouter_api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"HTTP-Referer\": \"https://localhost\",\n",
    "            \"X-Title\": \"ChromaDB Demo\"\n",
    "        }\n",
    "        data = {\n",
    "            \"model\": openrouter_model,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"max_tokens\": 2048,\n",
    "            \"temperature\": 0.7\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(url, headers=headers, json=data, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            return response.json()['choices'][0]['message']['content']\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"⚠️ OpenRouter API error: {str(e)}\")\n",
    "            return \"I couldn't process your request due to an API error.\"\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        return {\"model\": openrouter_model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d3b4ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Windows\\Temp\\ipykernel_13236\\2442575744.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "# Initialize components\n",
    "llm = RobustOpenRouterLLM()\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b74d95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data\n",
    "data_dir = os.path.join(os.getcwd(), \"data\")\n",
    "os.makedirs(data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddc5e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_files = {\n",
    "    \"sample.txt\": [\n",
    "        \"This is a sample document for testing ChromaDB with OpenRouter.\",\n",
    "        \"ChromaDB is a vector database that can be used for semantic search.\",\n",
    "        \"OpenRouter provides access to various LLM models through a unified API.\"\n",
    "    ],\n",
    "    \"ai_models.txt\": [\n",
    "        \"Large Language Models (LLMs) are transforming how we interact with AI.\",\n",
    "        \"Models like GPT-3.5, GPT-4, Claude, and Llama are available through OpenRouter.\",\n",
    "        \"Vector databases help store and retrieve embeddings for semantic search applications.\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "925fea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for filename, content in sample_files.items():\n",
    "    filepath = os.path.join(data_dir, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        with open(filepath, \"w\") as f:\n",
    "            f.write(\"\\n\".join(content))\n",
    "        print(f\"Created file: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c6f3c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 2 documents:\n",
      "\n",
      "Document: d:\\LLM_OPS\\Vector_Databases\\data\\ai_models.txt\n",
      "Content: Large Language Models (LLMs) are transforming how we interact with AI.\n",
      "Models like GPT-3.5, GPT-4, C...\n",
      "\n",
      "Document: d:\\LLM_OPS\\Vector_Databases\\data\\sample.txt\n",
      "Content: This is a sample document for testing ChromaDB with OpenRouter.\n",
      "ChromaDB is a vector database that c...\n"
     ]
    }
   ],
   "source": [
    "# Load documents\n",
    "loader = DirectoryLoader(data_dir, glob=\"**/*.txt\", loader_cls=TextLoader)\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"\\nLoaded {len(documents)} documents:\")\n",
    "for doc in documents:\n",
    "    print(f\"\\nDocument: {doc.metadata['source']}\")\n",
    "    print(f\"Content: {doc.page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9957609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ ChromaDB vector store created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create ChromaDB vector store\n",
    "vector_store = Chroma.from_documents(documents, embeddings)\n",
    "print(\"\\n✅ ChromaDB vector store created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "668ca886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create QA chain\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Answer based only on the provided context.\"),\n",
    "    (\"user\", \"Question: {question}\\nContext: {context}\")\n",
    "])\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "727549f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question: str, k: int = 2):\n",
    "    \"\"\"Helper function to ask questions and display results\"\"\"\n",
    "    try:\n",
    "        print(f\"\\nQuestion: {question}\")\n",
    "        \n",
    "        # Retrieve relevant documents\n",
    "        docs = vector_store.similarity_search(question, k=k)\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "        \n",
    "        # Get answer\n",
    "        answer = chain.invoke({\"question\": question, \"context\": context})\n",
    "        \n",
    "        print(f\"\\nAnswer: {answer}\")\n",
    "        \n",
    "        print(\"\\nSources used:\")\n",
    "        for i, doc in enumerate(docs):\n",
    "            print(f\"{i+1}. {doc.metadata['source']}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c57b524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: What is ChromaDB used for?\n",
      "\n",
      "Answer: ChromaDB is used for semantic search and can be integrated with OpenRouter to access various Large Language Models (LLMs) for AI interactions.\n",
      "\n",
      "Sources used:\n",
      "1. d:\\LLM_OPS\\Vector_Databases\\data\\sample.txt\n",
      "2. d:\\LLM_OPS\\Vector_Databases\\data\\ai_models.txt\n",
      "\n",
      "Question: What LLM models are available through OpenRouter?\n",
      "\n",
      "Answer: Based on the context provided, some of the LLM models available through OpenRouter include GPT-3.5, GPT-4, Claude, and Llama.\n",
      "\n",
      "Sources used:\n",
      "1. d:\\LLM_OPS\\Vector_Databases\\data\\sample.txt\n",
      "2. d:\\LLM_OPS\\Vector_Databases\\data\\ai_models.txt\n",
      "\n",
      "Question: How do vector databases help with AI applications?\n",
      "\n",
      "Answer: Vector databases help with AI applications by storing and retrieving embeddings for semantic search. They play a crucial role in enabling efficient and accurate search capabilities in AI systems like the LLM models available through OpenRouter.\n",
      "\n",
      "Sources used:\n",
      "1. d:\\LLM_OPS\\Vector_Databases\\data\\ai_models.txt\n",
      "2. d:\\LLM_OPS\\Vector_Databases\\data\\sample.txt\n"
     ]
    }
   ],
   "source": [
    "# Test the system\n",
    "ask_question(\"What is ChromaDB used for?\")\n",
    "ask_question(\"What LLM models are available through OpenRouter?\")\n",
    "ask_question(\"How do vector databases help with AI applications?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4021a46d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
