{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djiv2dTr4j_0",
        "outputId": "205e0e34-16be-4e88-a0a6-14dfcd20cfc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faiss-cpu in d:\\llm-ops\\llm_ops_env\\lib\\site-packages (1.11.0)\n",
            "Requirement already satisfied: numpy in d:\\llm-ops\\llm_ops_env\\lib\\site-packages (2.0.2)\n",
            "Requirement already satisfied: packaging in d:\\llm-ops\\llm_ops_env\\lib\\site-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GwOKk3b4yD8",
        "outputId": "9481c188-bf72-47ba-d1a8-824694854735"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai==0.28\n",
            "  Using cached openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in d:\\llm-ops\\llm_ops_env\\lib\\site-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in d:\\llm-ops\\llm_ops_env\\lib\\site-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in d:\\llm-ops\\llm_ops_env\\lib\\site-packages (from openai==0.28) (3.11.18)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\llm-ops\\llm_ops_env\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\llm-ops\\llm_ops_env\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\llm-ops\\llm_ops_env\\lib\\site-packages (from requests>=2.20->openai==0.28) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\llm-ops\\llm_ops_env\\lib\\site-packages (from requests>=2.20->openai==0.28) (2025.4.26)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\llm-ops\\llm_ops_env\\lib\\site-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in d:\\llm-ops\\llm_ops_env\\lib\\site-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in d:\\llm-ops\\llm_ops_env\\lib\\site-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in d:\\llm-ops\\llm_ops_env\\lib\\site-packages (from aiohttp->openai==0.28) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in d:\\llm-ops\\llm_ops_env\\lib\\site-packages (from aiohttp->openai==0.28) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\llm-ops\\llm_ops_env\\lib\\site-packages (from aiohttp->openai==0.28) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in d:\\llm-ops\\llm_ops_env\\lib\\site-packages (from aiohttp->openai==0.28) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\llm-ops\\llm_ops_env\\lib\\site-packages (from aiohttp->openai==0.28) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in d:\\llm-ops\\llm_ops_env\\lib\\site-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.13.2)\n",
            "Requirement already satisfied: colorama in d:\\llm-ops\\llm_ops_env\\lib\\site-packages (from tqdm->openai==0.28) (0.4.6)\n",
            "Using cached openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.77.0\n",
            "    Uninstalling openai-1.77.0:\n",
            "      Successfully uninstalled openai-1.77.0\n",
            "Successfully installed openai-0.28.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-openai 0.3.16 requires openai<2.0.0,>=1.68.2, but you have openai 0.28.0 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import faiss\n",
        "import requests\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ OpenRouter API key loaded successfully\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import faiss\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Get OpenRouter API key\n",
        "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "if not OPENROUTER_API_KEY:\n",
        "    print(\"⚠️ Warning: OPENROUTER_API_KEY not found in environment variables\")\n",
        "else:\n",
        "    print(f\"✅ OpenRouter API key loaded successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YNbHmx2m5BGc"
      },
      "outputs": [],
      "source": [
        "# Helper: Get embedding using OpenRouter API\n",
        "def get_embedding(text):\n",
        "    url = \"https://openrouter.ai/api/v1/embeddings\"\n",
        "    \n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
        "        \"HTTP-Referer\": \"https://localhost\",  # Required by OpenRouter\n",
        "        \"X-Title\": \"FAISS Demo\"  # Optional, but good practice\n",
        "    }\n",
        "    \n",
        "    data = {\n",
        "        \"model\": \"text-embedding-ada-002\",  # Use the correct embedding model\n",
        "        \"input\": text\n",
        "    }\n",
        "    \n",
        "    response = requests.post(url, headers=headers, json=data)\n",
        "    \n",
        "    # Debug information\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Error: {response.status_code}\")\n",
        "        print(f\"Response: {response.text}\")\n",
        "        raise Exception(f\"API request failed with status code {response.status_code}: {response.text}\")\n",
        "        \n",
        "    response_json = response.json()\n",
        "    \n",
        "    # Debug the response structure\n",
        "    if 'data' not in response_json:\n",
        "        print(f\"Unexpected response format: {response_json}\")\n",
        "        # Use a fallback method if OpenRouter fails\n",
        "        return get_fallback_embedding(text)\n",
        "        \n",
        "    embedding = response_json['data'][0]['embedding']\n",
        "    return np.array(embedding, dtype=np.float32)\n",
        "\n",
        "# Fallback method using a simple embedding technique\n",
        "def get_fallback_embedding(text):\n",
        "    print(\"Using fallback embedding method\")\n",
        "    # Create a simple hash-based embedding (not for production use)\n",
        "    import hashlib\n",
        "    # Create a fixed-size embedding of 1536 dimensions (same as OpenAI's)\n",
        "    embedding = np.zeros(1536, dtype=np.float32)\n",
        "    \n",
        "    # Fill the embedding with hash-based values\n",
        "    words = text.lower().split()\n",
        "    for i, word in enumerate(words):\n",
        "        hash_val = int(hashlib.md5(word.encode()).hexdigest(), 16)\n",
        "        for j in range(min(10, len(word))):\n",
        "            idx = (hash_val + j * i) % 1536\n",
        "            embedding[idx] = (hash_val % 10000) / 10000.0\n",
        "    \n",
        "    # Normalize the embedding\n",
        "    norm = np.linalg.norm(embedding)\n",
        "    if norm > 0:\n",
        "        embedding = embedding / norm\n",
        "        \n",
        "    return embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aKwTJg715NO7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: 404\n",
            "Response: {\"error\":{\"message\":\"Not Found\",\"code\":404}}\n",
            "❌ Embedding test failed: API request failed with status code 404: {\"error\":{\"message\":\"Not Found\",\"code\":404}}\n",
            "Falling back to hash-based embeddings for the demo\n"
          ]
        }
      ],
      "source": [
        "# Test the embedding function\n",
        "try:\n",
        "    test_text = \"This is a test sentence.\"\n",
        "    test_embedding = get_embedding(test_text)\n",
        "    print(f\"✅ Embedding test successful!\")\n",
        "    print(f\"Embedding shape: {test_embedding.shape}\")\n",
        "    print(f\"First 5 values: {test_embedding[:5]}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Embedding test failed: {str(e)}\")\n",
        "    print(\"Falling back to hash-based embeddings for the demo\")\n",
        "\n",
        "# Example texts\n",
        "texts = [\n",
        "    \"FAISS is a library for efficient similarity search.\",\n",
        "    \"It is developed by Facebook AI Research.\",\n",
        "    \"It supports cosine and L2 distance search.\",\n",
        "    \"You can use FAISS with OpenRouter embeddings.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating embeddings for all texts...\n",
            "Error: 404\n",
            "Response: {\"error\":{\"message\":\"Not Found\",\"code\":404}}\n",
            "❌ Error generating embeddings: API request failed with status code 404: {\"error\":{\"message\":\"Not Found\",\"code\":404}}\n",
            "Falling back to hash-based embeddings for all texts\n",
            "Using fallback embedding method\n",
            "Using fallback embedding method\n",
            "Using fallback embedding method\n",
            "Using fallback embedding method\n"
          ]
        }
      ],
      "source": [
        "# Get embeddings with error handling\n",
        "try:\n",
        "    print(\"Generating embeddings for all texts...\")\n",
        "    embeddings = np.array([get_embedding(text) for text in texts])\n",
        "    print(f\"✅ Successfully generated {len(embeddings)} embeddings\")\n",
        "    print(f\"Embedding dimensions: {embeddings.shape}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error generating embeddings: {str(e)}\")\n",
        "    print(\"Falling back to hash-based embeddings for all texts\")\n",
        "    embeddings = np.array([get_fallback_embedding(text) for text in texts])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cRdYc1n5X0D",
        "outputId": "d956aee9-3f0c-4413-ff9a-378de9cdc6df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "w1hxIK5V5Xxz"
      },
      "outputs": [],
      "source": [
        "# Normalize if using cosine similarity\n",
        "faiss.normalize_L2(embeddings)  # Optional: only if you're doing cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp9AV-jf5Xvc",
        "outputId": "e3878732-45ea-4dcf-c32f-ba4cc83e183a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1536\n"
          ]
        }
      ],
      "source": [
        "# Create FAISS index\n",
        "dimension = embeddings.shape[1]\n",
        "print(dimension)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mbDPAevT5fhk"
      },
      "outputs": [],
      "source": [
        "index = faiss.IndexFlatIP(dimension)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gh1UhyHA5jo8",
        "outputId": "ebf30df3-3009-4b2c-e497-ff476d613957"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<faiss.swigfaiss_avx2.IndexFlatIP; proxy of <Swig Object of type 'faiss::IndexFlatIP *' at 0x000001F87D8BAC90> >"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-KYeAzS75kf8"
      },
      "outputs": [],
      "source": [
        "# Add vectors to index\n",
        "index.add(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uUPipP-i5pxM"
      },
      "outputs": [],
      "source": [
        "# Store original texts for lookup\n",
        "text_id_map = {i: text for i, text in enumerate(texts)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcfJ89hc5pu0",
        "outputId": "ffeb5594-1f3f-43ab-8a0f-4b7c6f439b37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'FAISS is a library for efficient similarity search.',\n",
              " 1: 'It is developed by Facebook AI Research.',\n",
              " 2: 'It supports cosine and L2 distance search.',\n",
              " 3: 'You can use FAISS with OpenRouter embeddings.'}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_id_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Gl0Ry2bU5ukz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: 404\n",
            "Response: {\"error\":{\"message\":\"Not Found\",\"code\":404}}\n"
          ]
        },
        {
          "ename": "Exception",
          "evalue": "API request failed with status code 404: {\"error\":{\"message\":\"Not Found\",\"code\":404}}",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Query example\u001b[39;00m\n\u001b[0;32m      2\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is FAISS?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m query_vector \u001b[38;5;241m=\u001b[39m \u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m faiss\u001b[38;5;241m.\u001b[39mnormalize_L2(query_vector\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Normalize for cosine\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Search top 2 most similar\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[5], line 22\u001b[0m, in \u001b[0;36mget_embedding\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI request failed with status code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m response_json \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Debug the response structure\u001b[39;00m\n",
            "\u001b[1;31mException\u001b[0m: API request failed with status code 404: {\"error\":{\"message\":\"Not Found\",\"code\":404}}"
          ]
        }
      ],
      "source": [
        "# Query example\n",
        "query = \"What is FAISS?\"\n",
        "query_vector = get_embedding(query)\n",
        "faiss.normalize_L2(query_vector.reshape(1, -1))  # Normalize for cosine\n",
        "# Search top 2 most similar\n",
        "k = 2\n",
        "distances, indices = index.search(query_vector.reshape(1, -1), k)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lT6XAvA52_j",
        "outputId": "e52feabe-0d48-42e7-b12e-f9a4f3186b16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Result 1: FAISS is a library for efficient similarity search. (Score: 0.8826)\n",
            "Result 2: You can use FAISS with OpenAI embeddings. (Score: 0.8335)\n"
          ]
        }
      ],
      "source": [
        "# Display results\n",
        "for i, idx in enumerate(indices[0]):\n",
        "    print(f\"Result {i+1}: {text_id_map[idx]} (Score: {distances[0][i]:.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVdRkquP5290"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llm_ops_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
